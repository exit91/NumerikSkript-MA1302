%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Nichtlineare Systeme}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Problemstellung: Sei eine stetige Funktion
$F: \Omega \longrightarrow \mathbb{R}^n, \Omega \subset \mathbb{R}^n$ gegeben.
Gesucht ist $x^*\in \Omega$ mit $F(x^*)=0$.
\newline

\begin{bemerkung}
In der Regel existiert keine analytische Formel für $x^*$.
Es existiert kein Algorithmus, der nach endlich vielen Schritten exakt $x^*$
liefert.  Man ist daher auf Näherungsverfahren angewiesen.  Dieses Kapitel
liefert Konstruktionsansätze und untersucht Konvergenzeigenschaften.
\end{bemerkung}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Nullstellenbestimmung im Eindimensionalen}

Zunächst betrachten wir den Spezialfall $n=1$ und die stetige Funktion $f:
\mathbb{R} \longrightarrow \mathbb{R}$, die eine eindeutig bestimmte Nullstelle
$x^*$ besitzt. Geometrische Überlegungen sind die Grundlage für die folgende
Verfahren.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Bisektionsverfahren}

\begin{algorithm}
\caption{Bisektionsverfahren}
\begin{algorithmic}
\STATE Input: Startwerte $x_0, x_1, f$ mit $f(x_0) \cdot f(x_1) <0$\\
\FOR {$k = 1,2,3,...$}
  \STATE $x_{k+1} = \frac{1}{2} \cdot (x_k + x_{k-1})$
  \IF {$f(x_{k+1})\cdot f(x_{k-1})<0$}
    \STATE $x_k = x_{k-1}$
  \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}


\begin{bemerkung}
Jedes Iterationsverfahren muss mit einem Abbruchkriterium versehen werden.
\end{bemerkung}


\begin{enumerate}
\item[a)] Positiver Abbruch: Die aktuelle Lösung genügt einer vorgegebenen Genauigkeit
      (z.B: $|x_{k+1}-x_k|\leq TOL$).
\item[b)] Negativer Abbruch: Die Verfahrensvorschrift bricht zusammen z.B wegen Division durch 0
      oder es liegt keine oder nur sehr langsame Konvergenz vor. $\rightarrow k_{max}$
\end{enumerate}

\begin{lemma}
Das Bisektionsverfahren ist konvergent (global) unter der Voraussetzung:
$f(x_0) \cdot f(x_1) <0$. Im k-ten Schritt gilt: $|x^*-x_{k+1}|\leq
(\frac{1}{2})^k \cdot |x_1-x_0|$ 
\end{lemma}

\begin{proof}
~
\begin{enumerate}
\item[a)] In jedem Schritt wird das aktuelle Intervall halbiert. 
\item[b)] Die Auswahl des neuen Intervalls erfolgt so, dass $x^*$ darin
enthalten ist\footnote{Nach Zwischenwertsatz: Für jede stetige Funktion
$f$ auf einem offenen Intervall $[a,b]$ gilt: $f(a)\cdot(b) < 0 \Rightarrow \exists \xi \in [a,b]$ mit $f(\xi) = 0$}.
\end{enumerate}
\end{proof}

Trotz der Konvergenzaussage findet das Verfahren in der Praxis kaum Verwendung!
($\rightarrow$ langsame Konvergenz, Systemfall\footnote{Für den engagierten
Leser: Wer hat eine Definition für ``Systemfall''?})

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Sekantenverfahren}

Eine Sekantengleichung ist durch $(x_k, f(x_k))$ und $(x_{k-1}, f(x_{k-1}))$ gegeben.
\newline
$s(x)=\frac{f(x_{k-1})}{x_{k-1}-x_k} \cdot (x-x_k)+\frac{f(x_k)}{(x_k-x_{k-1})}\cdot (x-x_{k-1})$
\newline
Berechne $\tilde x$, sodass $s(\tilde x)=0$

\begin{algorithm}
\caption{Sekantenverfahren}
\begin{algorithmic}
\STATE Input: Startwerte $x_0, x_1, f$
\FOR {$k=1,2,3...$}
  \STATE $x_{k+1} = x_k - \frac{x_k-x_{k-1}}{f(x_k)-f(x_{k-1})} \cdot f(x_k)$
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{bemerkung}
Im Gegensatz zum Bisektionsverfahren, kann
\begin{enumerate}
\item[a)] es zum ungewollten Abbruch kommen.
\item[b)] Divergenz auftreten.
\end{enumerate}

Abhilfe: Regula falsi kombiniert die beiden Verfahren, dh.
\begin{enumerate}
\item  $x_{k+1}$ wird aus der Sekantenformel berechnet.
\item  ob mit $(x_{k+1},x_k)$ oder mit $(x_{k+1},x_{k-1})$ weitergerechnet wird, entscheiden die Vorzeichen.
\end{enumerate}
\end{bemerkung}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Fixpunktiterationen}

Einen abstrakten Rahmen liefert der Banach'sche Fixpunktsatz aus der Analysis.
\newline

\noindent Sei $\Omega$ eine abgeschlossene Teilmenge des $\mathbb{R}^n$ und $\Phi: \Omega
\longrightarrow \Omega$ eine Kontraktion, dh. $\exists \ q<1: \| \Phi(x) -
\Phi(y)\| \leq q\cdot \|x-y\|~\forall x,y \in \mathbb{R}^n$, so besitzt $\Phi$
genau einen Fixpunkt, dh. ein $x^*$ mit $\Phi(x^*)=x^*$.  Um von dieser Aussage
profitieren zu können, müssen wir zunächst die Problemstellung umformulieren.
Dazu wird zu vorgegebenem $F$ ein $\Phi$ bestimmt, sodass aus $\Phi(x^*)=x^*
\Rightarrow F(x^*)=0$.

\begin{tabbing}
\textbf{Beispiel:}
\\$f(x)=2-x^2-e^x$, gesucht $x^*>0$ mit $f(x^*)=0$\\
\hspace*{8mm} \=$\varphi_1(x)=\sqrt{2-e^x}$\\
\>$\varphi_2(x)=ln(2-x^2)$\\
\end{tabbing}

\begin{definition} [Fixpunktiteration]
Ausgehend von der Iterationsfunktion $\Phi$ und einem Startwert $x_0$ definiert
man die Iterationsfolge\footnote{Notation: In dieser Vorlesung entspricht
$\{a_n\}_{n=1}$ der aus der Analysis 1 bekannten Notation $(a_n)_{n\geq 1}$}
$\{x_k\}_{k=0}$ durch $x_{k+1}=\Phi(x_k)$.
\end{definition}

\begin{lemma}[Konvergenz]
~ % erzwinge einen zeilenumbruch
\begin{enumerate}
\item[a)] Sei $\Phi$ stetig und $x_k \longmapsto x^*$, so gilt $\Phi(x^*)=x^*$
\item[b)] Sei $\Phi: \Omega \longrightarrow \Omega$ \ ($\Omega$ abgeschlossen) eine Kontraktion, so konvergiert die Fixpunktiteration.
\end{enumerate}
\end{lemma}

\begin{proof}
~
\begin{enumerate}
\item[a)] $x^*=\lim_{k \to \infty}x_k=\lim_{k \to \infty}\Phi(x_{k-1})=\Phi(\lim_{k \to \infty}x_{k-1})=\Phi(x^*)$
\item[b)] % TODO, alignment  stimmt vorne und hinten nicht ^^
$\left\{\begin{aligned}
\|x_{k+1}-x_k\| = \|\Phi(x_k)-\Phi(x_{k-1})\| &\leq q\cdot \|x_k-x_{k-1}\| \\
                                              &\leq q^2\cdot \|x_{k-1}-x_{k-2}\| \\
                                   \leq \cdots&\leq q^k\cdot \|x_1-x_0\|
\end{aligned}\right.$
\end{enumerate}

Daraus folgt, dass $\{x_k\}$ eine Cauchyfolge ist, da
\begin{align*}
\|x_{k+m}-x_k\|&\leq \underbrace{\|x_{k+m}-x_{k+m-1}\|}_{\leq q^{k+m-1}\cdot \|x_1-x_0\|}
                  +\underbrace{\|x_{k+m-1}-x_{k+m-2}\|}_{\leq q^{k+m-2}\cdot \|x_1-x_0\|}
                  +\cdots
                  +\underbrace{\|x_{k+1}-x_k\|}_{\leq q^k\cdot \|x_1-x_0\|} \\
               &\leq q^k\|x_1-x_0\| \cdot (1+q+q^2+\cdots +q^{m-1})\\
               &\leq q^k\|x_1-x_0\| \cdot \frac{1}{1-q} \quad \mbox{(geometrische Reihe!)}
\end{align*}

Da $\Omega$ abgeschlossen, konvergiert $x_k$ gegen $x^* \in \Omega$.
\end{proof}

\noindent\textbf{Beispiel:} Sekantenverfahren im $\mathbb R^2$ \\\newline
$\Phi(y)=
\begin{pmatrix}
y_2 \\
y_2-\frac{y_2-y_1}{f(y_2)-f(y_1)}\cdot f(y_2)
\end{pmatrix}, \quad y\in \mathbb{R}^2$\\
\newline

\begin{definition}[Konvergenzordnung]
~
\begin{enumerate}
\item Eine Folge $\{x_k \}_{k\in\mathbb{N}}$ heißt konvergent von der Ordnung $p\geq 1$ gegen $x^*$,
falls gilt $\| x_{k+1}-x^*\|\leq C\cdot \|x_k-x^*\|^p$ und für $p=1$ wird gefordert, dass $C<1$ gilt.
(``linear konvergent'' bezeichnet den Fall $p=1$, ``quadratisch konvergent'' den Fall
$p=2$, \ldots) % verwende \ldots statt $\cdots$ wegen Text-Alignment (l = low, c = center)
\item Der Fall $\lim_{k \to \infty}\frac{\|x_{k+1}-x^*\|}{\|x_k -x^*\|}=0$ heißt superlineare Konvergenz.
\item Eine Fixpunktiteration heißt
  \begin{enumerate}
  \item lokal konvergent von der Ordnung $p$, falls eine offene Umgebung $U$ von $x^*$ existiert,
        sodass jede Iterationsfolge $\{x_k\}_{k=0}$ mit $x_0\in U$ konvergent
        von der Ordnung $p$ gegen $x^*$ ist.
  \item global konvergent von der Ordnung $p$, falls für jede Iterationsfolge
        $\{x_k\}_{k=0}$ mit $x_0\in \Omega$ konvergent von der Ordnung $p$
ist.\footnote{Frage: Muss in dieser Definition $x^*$ für jedes $x_0$ gleich sein?} %TODO
  \end{enumerate}
\end{enumerate}
\end{definition}

%\pagebreak
\begin{lemma}[Superlineare Konvergenz des Sekantenverfahrens]
Sei $f$ zweimal stetig differenzierbar und $x^*$ eine einfache Nullstelle, so
konvergiert das Sekantenverfahren lokal mit $p=\frac{1+\sqrt{5}}{2}$
(goldener Schnitt).
\end{lemma}

\begin{proof}
Definiere
\begin{align*}
f[x,y]   &:= \frac{f(y)-f(x)}{y-x} \\
f[x,y,z] &:= \frac{f[y,z]-f[x,y]}{z-x}
\end{align*}

Dann gilt\footnote{Diese Berechnung wurde um einige Zwischenschritte erweitert,
was hoffentlich nicht stört} (mit $-f(x_k) = f(x^*)-f(x_k) = (x^*-x_k)\cdot f[x_k,x^*]$):
\begin{align*}
  x_{k+1}&=x_k-\frac{f(x_k)}{f[x_{k-1},x_k]} = x_k + (x^*-x_k)\frac{f[x_k,x^*]}{f[x_{k-1},x_k]}
\\x_{k+1}-x^*& = (x_k - x^*) - (x_k-x^*)\frac{f[x_k,x^*]}{f[x_{k-1},x_k]} =
(x_k-x^*)\cdot (1-\frac{f[x_k,x^*]}{f[x_{k-1},x_k]})
\\&=\frac{(x_k-x^*)\cdot(x_{k-1}-x^*)}{f[x_{k-1},x_k]}\cdot (f[x_{k-1},x_k,x^*])
\end{align*}

Da $f\in C^2$ folgt aus dem Mittelwertsatz der Differentialrechnung:
\begin{align*}
f[x_{k-1},x_k]     =f'(\eta_k), \ \eta_k\in [\min(x_k,x_{k-1}), \max(x_k,x_{k-1})] \\
f[x_{k-1},x_k,x^*] =\frac{1}{2}\cdot f''(\xi_k), \ \xi_k\in [\min(x_k,x_{k-1},x^*), \max(x_k,x_{k-1},x^*)]\\
\end{align*}

Weiterhin gilt $f'(x^*)\neq 0$ und somit existiert ein $\varepsilon > 0$ und ein $M<\infty$ mit
\[ % alleinstehende formel
  \left| \frac{f''(\xi)}{2\cdot f'(\eta)} \right|<M \ \ \forall \ \xi,\eta\in
[x^*-\varepsilon,x^*+\varepsilon]=:\overline{W}
\]

Sei nun $\delta:= \min (\frac{1}{M},\varepsilon)$ und
$U:=(x^*-\delta,x^*+\delta)\subset \overline{W}$.
Seien $x_0, x_1\in U$ und $e_k:=M\cdot \|x_k-x^*\|$, so gilt:
\begin{align}
e_k< \min(1,\varepsilon \cdot M)  & \mbox{ für } k\geq 0 \label{eq:prop1}\\ % TODO: >= oder > ?
x_k\in U                          & \mbox{ für } k\geq 0 \label{eq:prop2}\\ %
e_k\leq e_{k-1}\cdot e_{k-2}      & \mbox{ für } k\geq 2 \label{eq:prop3}   %
\end{align}

Für $k=0,1$ \checkmark\newline

Induktiv erhält man, falls $x_{k-2},x_{k-1}\in U$, dass
\[
  e_k=\frac{1}{M}\cdot e_{k-1}\cdot e_{k-2}\cdot \underset{<M}{\underbrace{\left|\frac{f''(\xi_{k-1})}{2\cdot
  f'(\eta_{k-1})}\right|}} \Rightarrow \mbox{ \eqref{eq:prop1}, \eqref{eq:prop3}}
\]
\[
  \|x_k-x^*\|=\frac{e_k}{M}<\min(\frac{1}{M},\varepsilon)=\delta\Rightarrow
x_k\in U\Rightarrow \mbox{ \eqref{eq:prop2} }
\]
Da $e_0,e_1<1$ gilt $L:=\max(e_0,e_1^{1/p})<1$. Mehr noch: $e_0\leq L$,
$e_1\leq L^p$. Induktiv ergibt sich daraus $e_k\leq L^{p^k}$ für $k\geq 0$, % TODO: >= oder > ?
da\marginpar{Eigenschaft des goldenen Schnitts: $1+p = p^2$}
\[
  e_k\leq e_{k-1}\cdot e_{k-2}\leq L^{p^{k-1}}\cdot L^{p^{k-2}}=L^{p^{k-2}\cdot
(1+p)} = L^{p^k}
\]\[
  \Rightarrow e_k\leq (L^{p^{k-1}})^p
\]
\end{proof}

% Vorlesung vom 23. Aug 2011:

\begin{lemma}
\label{lem:kvg-ord}
\noindent Sei $\Phi \in C^1(a,b)$ und $x^*\in (a,b)$ ein Fixpunkt, dann ist die Fixpunktiteration
\begin{enumerate}
\item[a)] lokal konvergent, falls $|\Phi'(x^*)|<1$
\item[b)] divergent, falls $|\Phi'(x^*)|>1$
\item[c)] lokal konvergent von der Ordnung $p$, falls
  $\Phi\in C^p$ mit $\Phi^{(l)}(x^*)=0$ für $l=1,\ldots ,p-1$
  und $\Phi^{(p)}(x^*)\neq 0$
\end{enumerate}
\end{lemma}

\begin{proof}
~
\begin{enumerate}
\item[a)] Der Beweis erfolgt in 3 Schritten:
\begin{enumerate}
\item[1)] Definition einer Umgebung $\mathcal U:=(x^*-\varepsilon,x^*+\varepsilon)$,
  wobei $\varepsilon$ so gewählt wird, dass $|\Phi'(x)|\leq\alpha<1 ~\forall x\in \mathcal U$
\item[2)] Sei $x_0\in \mathcal U$, so gilt\footnote{Verwendet wird eine
Taylorentwicklung mit Restgliedabschätzung(?)}:
\begin{align*}
x_1&=\Phi (x_0)=\underset{=x^*}{\underbrace{\Phi(x^*)}}+\Phi'(\xi)\cdot
(x_0-x^*)\text{ mit }\xi\in \mathcal U \\
&\Rightarrow |x_1-x^*|=\underset{< 1}{\underbrace{|\Phi'(\xi)|}}\cdot |x_0-x^*|<|x_0-x^*| \\
&\Rightarrow x_1\in \mathcal U\Rightarrow \text{(Induktion)}\cdots\Rightarrow x_k\in \mathcal U \ \ \forall k\geq1
\end{align*}
\item[3)]Wegen $\alpha<1$, $\lim_{k \to\infty}{\alpha^k}=0$ folgt
\begin{align*} |x_k-x^*|&=|\Phi(x_{k-1})-\Phi(x^*)|\leq |\Phi'(\xi_k)|\cdot |x_{k-1}-x^*| \\
&\leq
  \underset{k \text{ Faktoren}}{\underbrace{|\Phi'(\xi_k)|\cdot
  |\Phi'(\xi_{k-1})|\cdots}} |x_0-x^*|\leq \alpha^k\cdot |x_0-x^*|\to 0
\end{align*}
\end{enumerate}
\item[b)] analog zu a)
\item[c)] Konvergenz folgt aus a), Ordnung folgt aus Taylorentwicklung.
\end{enumerate}
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Newton-Verfahren}

Das am häufigsten verwendete numerische Verfahren ist das Newton-Verfahren. Im
Gegensatz zu den bisherigen Verfahren ist es nicht auf den eindimensionalen
Raum beschränkt.

\begin{algorithm}
\caption{Allgemeines Newton-Verfahren}
\begin{algorithmic}
\STATE Input: Startwert $x_0, F$
\FOR {$k=0,1,2,...$}
  \STATE $J_F(x_k)\cdot \Delta x=F(x_k)$  \COMMENT{Löse das lineare
                                          Gleichungssystem nach $\Delta x$}
  \STATE $x_{k+1}=x_k-\Delta x$           \COMMENT{Korrigiere $x_k$}
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{bemerkung}
Das Verfahren ist im k-ten Schritt wohldefiniert,
falls $\det(J_F(x_k))\neq 0$.\\ % Verwende den \det Befehl für ein besseres
                                % Schriftbild
Fall $n=1:$
\begin{align*}
\Phi(x)     &=x-\frac{f(x)}{f'(x)},\\
\Phi'(x)    &=1-\frac{{f'(x)}^2-f''(x)\cdot f(x)}{{f'(x)}^2}\\
            &=1-1+\frac{f''(x)\cdot f(x)}{{f'(x)}^2}\\
            &\Rightarrow \Phi'(x^*)=0\\
\Phi''(x)   &=\text{Dem Leser überlassen} \\
\end{align*}
Daraus schließen wir nach Lemma \ref{lem:kvg-ord} die quadratische Konvergenz von der Ordnung 2 im eindimensionalen
Fall.
\end{bemerkung}

\begin{lemma}[Konvergenz des Newtonverfahrens]
Sei $F:\Omega \longrightarrow \mathbb{R}^n$ ($\Omega$ offen und konvex)
eine stetig differenzierbare Funktion. Die Jacobi-Matrix sei überall invertierbar
und genüge folgender Lipschitz-Bedingung: Es existiert ein $w<\infty$ mit der Eigenschaft:
Für alle $x\in \Omega, v\in \mathbb{R}^n \text{ mit } x+v\in \Omega \text{ und }
s\in [0,1]$ gilt:
\[
\|{J_F(x)}^{-1}\cdot (J_F(x+s\cdot v)-J_F(x))\cdot v\|\leq s\cdot  w \|v\|^2 \quad
\]
Weiterhin sei $x^*\in \Omega$ eine einfache Nullstelle von $F$ und $\|x_0-x^*\|:=\delta<\frac{2}{ w}$, so konvergiert die durch das Newton-Verfahren erzeugte Folge $\{x_k\}_{k\in \mathbb{N}}$ mindestens quadratisch gegen $x^*$. 
\end{lemma}

\begin{proof}
\begin{align*}
x_{k+1}-x^*
  &= x_k-x^*-\underset{\Delta x}{\underbrace{{J_F(x_k)}^{-1}\cdot F(x_k)}}\\
  &= {J_F(x_k)}^{-1}\cdot (\underset{=0}{\underbrace{F(x^*)}}-F(x_k)+J_F(x_k)\cdot (x_k-x^*))\\
  &\qquad\text{Durch Anwendung des Hauptsatzes der Integralrechnung erhalten wir: } \\
  &\qquad F(x^*)-F(x_k) = \int_{0}^1 J_F(x_k+s\cdot (x^*-x_k))\cdot (x^*-x_k)\,ds\\
  &\qquad \text{und setzen ein:} \\
%
  &= {J_F(x_k)}^{-1}\cdot ( \int_{0}^1 J_F(x_k+s\cdot (x^*-x_k))\cdot (x^*-x_k)\,ds +J_F(x_k)\cdot (x_k-x^*))\\
%
  &= \int_{0}^1 {J_F(x_k)}^{-1}\cdot (J_F(x_k+s\cdot(x^*-x_k))-J_F(x_k))\cdot (x^*-x_k)\,ds\\
\Rightarrow \| x_{k+1}-x^*\|
  & = \int_{0}^1 s\cdot  w \cdot {\| x^*-x_k\|}^2\,ds \quad\text{ \ (nach Voraussetzung mit $v=x^*-x_k$)}\\
  &\leq w \cdot {\| x^*-x_k\|}^2\,\int_0^1s~ds \\
&=\frac{1}{2}\cdot  w \cdot {\| x^*-x_k\|}^2
\end{align*}

\noindent Die Folgerung $\|x_1-x^*\|\leq \frac{1}{2}\cdot  w \cdot {\| x^*-x_0\|}^2<\frac{1}{2}\cdot  w
\cdot \frac{4}{{ w}^2}=\frac{2}{ w}$ zeigt sowohl lokale quadratische
Konvergenz sowie die Beschränktheit der Iterationsfolge(?)\footnote{Soll dies
zeigen, dass die Folgenelemente eine gewisse Umgebung nie verlassen? Wir haben
eine solche innerhalb dieses Beweises nie eingeführt!}.
Durch Induktion folgt: $\|x_k-x^*\|<\frac{2}{ w}$, \ $\forall k \geq 1$.
\end{proof}

\begin{bemerkung}
~
\begin{enumerate}
\item[1)] Um den lokalen Konvergenzbereich zu vergrößern, arbeitet man mit gedämpften Varianten $x_{k+1}=x_k-\lambda_k\cdot \Delta x$, \ $\lambda\in (0,1]$.
\end{enumerate}

\end{bemerkung}
